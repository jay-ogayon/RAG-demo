{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List, Dict\n",
    "\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import MongoDBAtlasVectorSearch\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "from langchain.chains import ConversationalRetrievalChain, SequentialChain, LLMChain\n",
    "from langchain.memory import MongoDBChatMessageHistory, ConversationBufferMemory\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema import Document\n",
    "\n",
    "from pymongo import MongoClient\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up API keys and connection strings\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your-api-key-here\"\n",
    "MONGODB_ATLAS_CLUSTER_URI = \"your-mongodb-atlas-connection-string\"\n",
    "\n",
    "# Set up MongoDB client and collections\n",
    "client = MongoClient(MONGODB_ATLAS_CLUSTER_URI)\n",
    "db = client[\"your_database_name\"]\n",
    "vector_collection = db[\"your_vector_collection_name\"]\n",
    "chat_history_collection = db[\"chat_history\"]\n",
    "\n",
    "# Initialize language model\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo\")\n",
    "\n",
    "# Load and split documents\n",
    "loader = TextLoader(\"path/to/your/document.txt\")\n",
    "documents = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "split_docs = text_splitter.split_documents(documents)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vector store\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vector_store = MongoDBAtlasVectorSearch.from_documents(\n",
    "    split_docs,\n",
    "    embeddings,\n",
    "    collection=vector_collection,\n",
    "    index_name=\"your_index_name\"\n",
    ")\n",
    "\n",
    "# Create compressed retriever\n",
    "base_retriever = vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5})\n",
    "compressor = LLMChainExtractor.from_llm(llm)\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=base_retriever\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up chat history and memory\n",
    "message_history = MongoDBChatMessageHistory(\n",
    "    connection_string=MONGODB_ATLAS_CLUSTER_URI,\n",
    "    database_name=\"your_database_name\",\n",
    "    collection_name=\"chat_history\",\n",
    "    session_id=\"user_123\"  # This could be a unique identifier for each user or conversation\n",
    ")\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    input_key=\"human_input\",\n",
    "    chat_memory=message_history\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up query optimization chain\n",
    "summarize_prompt = PromptTemplate(\n",
    "    template=\"Summarize the chat history:\\n\\n{chat_history}\\n\\nSummary:\",\n",
    "    input_variables=[\"chat_history\"]\n",
    ")\n",
    "summarize_chain = LLMChain(llm=llm, prompt=summarize_prompt, output_key=\"history_summary\")\n",
    "\n",
    "concept_prompt = PromptTemplate(\n",
    "    template=\"Identify key concepts in this query and history summary:\\n\\nHistory: {history_summary}\\nQuery: {query}\\n\\nKey Concepts:\",\n",
    "    input_variables=[\"history_summary\", \"query\"]\n",
    ")\n",
    "concept_chain = LLMChain(llm=llm, prompt=concept_prompt, output_key=\"key_concepts\")\n",
    "\n",
    "optimize_prompt = PromptTemplate(\n",
    "    template=\"Optimize this query based on the history and concepts:\\n\\nHistory: {history_summary}\\nConcepts: {key_concepts}\\nQuery: {query}\\n\\nOptimized Query:\",\n",
    "    input_variables=[\"history_summary\", \"key_concepts\", \"query\"]\n",
    ")\n",
    "optimize_chain = LLMChain(llm=llm, prompt=optimize_prompt, output_key=\"optimized_query\")\n",
    "\n",
    "query_optimizer = SequentialChain(\n",
    "    chains=[summarize_chain, concept_chain, optimize_chain],\n",
    "    input_variables=[\"chat_history\", \"query\"],\n",
    "    output_variables=[\"optimized_query\"],\n",
    "    verbose=True\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up RAG chain\n",
    "rag_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=compression_retriever,\n",
    "    memory=memory,\n",
    "    condense_question_prompt=PromptTemplate.from_template(\"{chat_history}\\n\\nHuman: {question}\\n\\nAI: To better assist you, I'll rephrase your question. Here's the optimized query:\"),\n",
    "    condense_question_llm=query_optimizer\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example conversation\n",
    "queries = [\n",
    "    \"What is artificial intelligence?\",\n",
    "    \"What are its main applications?\",\n",
    "    \"Can you summarize what we've discussed about AI so far?\"\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    result = rag_chain({\"question\": query})\n",
    "    print(f\"Human: {query}\")\n",
    "    print(f\"AI: {result['answer']}\\n\")\n",
    "\n",
    "# Display chat history\n",
    "print(\"Chat History:\")\n",
    "for message in message_history.messages:\n",
    "    print(f\"{message.type}: {message.content}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
